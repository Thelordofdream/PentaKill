# 人工智能与机器学习

## 招商银行·网络科技

#### 卷积神经网络和深度神经网络这两个概念有什么区别？
* 卷积神经网络是指用卷积层作为特征提取的神经网络，而深度神经网络包括了如Deep Q Network、RNN、LSTM等层数很深的神经网络算法

#### Word2Vec的两个核心算法是什么？
* CBOW(Continuous Bag-of-Words Model)和Skip-gram(Continuous Skip-gram Model)。CBOW是已知上下文词汇，预测当前词汇，给出当前词的最大似然估计；Skip-gram是已知当前次会，预测上下文词汇，给出上下文的最大似然估计

#### 处理现在的卷积神经网络算法有哪些不足？
* 处理高分辨率的图像，计算量会成指数暴涨
* 无法处理图像发生旋转变换的情况
* 在高噪声情况下，神经网络易受欺骗
* 对超参数有很强的依赖，初始化和调参困难
* 层次过深的模型，很容易发生梯度消散或爆炸而无法收敛
* 池化层的信息缺失(改进方法：增加数据和胶囊网络)

#### 对于支持向量机，有什么方法可以防止过拟合？
* 加入松弛项，使得数据点可以不严格分布于Margin之外

#### 对过拟合和欠拟合有什么理解？
* 数据集是对研究对象的抽样，并不能完全反应真实的分布情况。过拟合，就是对抽样的数据集有很好的拟合效果，但是偏离了真实分布而陷入真实分布的局部最优。欠拟合，就是对抽样的数据集本身拟合不足，无法很好地反映数据集的分布情况

#### 深度学习有什么不适合应用的场景？
* 数据维度非常低或者非常稀疏的问题
* 

#### 使用TensorFlow手写一个CNN
    import tensorflow as tf

## 百度
#### 逻辑斯谛回归的目标函数是什么？
* 目标函数是损失函数+正则项。逻辑斯谛回归的目标函数是：  
<img src="http://latex.codecogs.com/gif.latex?L(w)=-\sum_{i=1}^{n}[y_{i}log(\sigma(w^{T}x_{i}))+(1-y_{i})log(1-\sigma(w^{T}x_{i}))]+\lambda\sum_{i=1}^{n}\lVert w_{i}\rVert">
	
#### 如何训练逻辑斯谛回归中的权重参数？
* 梯度下降/牛顿法/拟牛顿法，来更新参数

#### 随机梯度下降和梯度下降有什么区别？
* 梯度下降是直接在整个数据集上计算损失函数并更新权重，获取的是全局梯度；而随机梯度下降是每次随机抽取一部分的数据计算来更新权重，获取的不是随机梯度。

#### 逻辑斯谛回归是线性的吗？为什么？
* 是线性的，因为<img src="http://latex.codecogs.com/gif.latex?w^{T}x">仍然是一个一阶线性的。

#### 训练Word2Vec的两个方法是什么？
* Hierarchical Softmax和Negative Sampling。前者是训练一棵霍夫曼树；后者摒弃了霍夫曼树。

#### RNN存在什么问题？
* 存在长期依赖问题，也就是在梯度在前向传播中消散。

#### LSTM是如何解决长期依赖问题的？
* 在LSTM中输入门、输出门、隐含状态中采用了梯度截断法的近似，对这三个门的梯度直接取为0值，因为当前时刻的损失值对前一时刻的损失值偏导保持为1，因为损失值在前向传播中并不会衰减。

#### 有哪些技术可以防止梯度消散或者爆炸？
* Skip Gradient
* Batch normalization

#### 有哪些激活函数？
* Sigmoid函数，Softmax函数，ReLu函数，tanh函数

#### Deep Q Learning中的Experience Replay是什么？
* Experience Replay又称“经验池”，是将每个时间步Agent于环境交互得到的转移样本储存起来<img src="http://latex.codecogs.com/gif.latex?(S_{t},A_{t},R_{t},S_{t+1})">，然后训练时随机采样样本更新深度神经网络的参数。

#### REINFORCE模型是什么？
* REINFORCE是policy based的强化学习模型，只有状态State和奖励Reward，将状态的转移作为决策的结果。

#### 程序实现树转化成序列，实现序列转化成树？
    def Seqlize(tree):
      if !tree:
         

#### 有一个m长的数列，设计算法取出其中最大的10个数；如何优化算法，使算法复杂度达到<img src="http://latex.codecogs.com/gif.latex?O(mlog10)">和<img src="http://latex.codecogs.com/gif.latex?O(m)">
* 取头10个数值降序存入10长度的数列中，向后遍历原数列，将新值与数列中的数进行比较，如大于最小值则插入适当位置保持数列降序，小于最小值泽忽略，不断更新数列直到遍历完成；时间复杂度为10m。将10长度的数列变成堆；时间复杂度为<img src="http://latex.codecogs.com/gif.latex?mlog10">。
 
#### 快排的原理是怎么样的？快排的复杂度是多少？
* 简单而言，快排的原理是。快排的平均复杂度是<img src="http://latex.codecogs.com/gif.latex?nlogn">，最坏情况是<img src="http://latex.codecogs.com/gif.latex?n^{2}">。

#### 手推GBDT与XGBoost
* http://blog.csdn.net/asd136912/article/details/78556362
* https://www.jianshu.com/p/7467e616f227

#### XGBoost中shrinkage
* Shrinkage（缩减），即学习速率 将学习速率调小，迭代次数增多，有正则化作用
#### 讲解一下你的项目（抽象文本摘要）#Appended by Chen Liyu,2018.03.25
https://arxiv.org/pdf/1704.04368.pdf

## 网易游戏
#### 简单说下什么是大小端
* 大端是指，数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中。类似于将数据当做字符串顺序处理，和我们的阅读习惯一致。
* 小端是指，数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中。这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低。

#### 推荐算法运用在游戏虚拟物品推荐中与在淘宝等购物网站中有什么不同
* 在游戏虚拟物品推荐中，数据更稀疏（人民币玩家只占所有玩家的一小部分，很多玩家没有购买记录；而淘宝上的用户几乎都曾购买过商品），数据冷启动的问题更显著

#### GRU相对于LSTM的优点
* GRU模型参数更少，构造更简单，方便训练

#### 0，1，2，3，4 每次从这五个数字中随机抽取一个数字（有放回），遇到重复数字就停止，求抽取次数的数学期望
* 例如： 1，2，1 （3次） 0，1，2，3，1 （5次）
* 暂时没找到解法...