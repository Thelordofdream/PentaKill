# 人工智能与机器学习

## 招商银行·网络科技

#### 卷积神经网络和深度神经网络这两个概念有什么区别？
* 卷积神经网络是指用卷积层作为特征提取的神经网络，而深度神经网络包括了如Deep Q Network、RNN、LSTM等层数很深的神经网络算法

#### Word2Vec的两个核心算法是什么？
* CBOW(Continuous Bag-of-Words Model)和Skip-gram(Continuous Skip-gram Model)。CBOW是已知上下文词汇，预测当前词汇，给出当前词的最大似然估计；Skip-gram是已知当前次会，预测上下文词汇，给出上下文的最大似然估计

#### 处理现在的卷积神经网络算法有哪些不足？
* 处理高分辨率的图像，计算量会成指数暴涨
* 无法处理图像发生旋转变换的情况
* 在高噪声情况下，神经网络易受欺骗
* 对超参数有很强的依赖，初始化和调参困难
* 层次过深的模型，很容易发生梯度消散或爆炸而无法收敛
* 池化层的信息缺失(改进方法：增加数据和胶囊网络)

#### 对于支持向量机，有什么方法可以防止过拟合？
* 加入松弛项，使得数据点可以不严格分布于Margin之外

#### 对过拟合和欠拟合有什么理解？
* 数据集是对研究对象的抽样，并不能完全反应真实的分布情况。过拟合，就是对抽样的数据集有很好的拟合效果，但是偏离了真实分布而陷入真实分布的局部最优。欠拟合，就是对抽样的数据集本身拟合不足，无法很好地反映数据集的分布情况

#### 深度学习有什么不适合应用的场景？
* 数据维度非常低或者非常稀疏的问题
* 

#### 使用TensorFlow手写一个CNN
    import tensorflow as tf

## 百度
#### 逻辑斯谛回归的目标函数是什么？
* 目标函数是损失函数+正则项。逻辑斯谛回归的目标函数是：
<img align = "center" src="http://latex.codecogs.com/gif.latex?L(w) = -\sum_{i=1}^{n} [y_{i}log(\sigma(w^{T}x_{i}))+(1-y_{i})log(1-\sigma(w^{T}x_{i}))] + \lambda\sum_{i=1}^{n} \lVert w_{i} \rVert">
	
#### 如何训练逻辑斯谛回归中的权重参数？
* 梯度下降/牛顿法/拟牛顿法，来更新参数

#### 随机梯度下降和梯度下降有什么区别？
* 梯度下降是直接在整个数据集上计算损失函数并更新权重，获取的是全局梯度；而随机梯度下降是每次随机抽取一部分的数据计算来更新权重，获取的不是随机梯度。

#### 逻辑斯谛回归是线性的吗？为什么？
* 是线性的，因为<img src="http://latex.codecogs.com/gif.latex?w^{T}x">仍然是一个一阶线性的。

#### 训练Word2Vec的两个方法是什么？
* Hierarchical Softmax和Negative Sampling。前者是训练一棵霍夫曼树；后者摒弃了霍夫曼树。

#### RNN存在什么问题？
* 存在长期依赖问题，也就是在梯度在前向传播中消散。

#### LSTM是如何解决长期依赖问题的？
* 在LSTM中输入门、输出门、隐含状态中采用了梯度截断法的近似，对这三个门的梯度直接取为0值，因为当前时刻的损失值对前一时刻的损失值偏导保持为1，因为损失值在前向传播中并不会衰减。

#### 有哪些技术可以防止梯度消散或者爆炸？
* Skip Gradient
* Batch normalization

#### 有哪些激活函数？
* Sigmoid函数，Softmax函数，ReLu函数，tanh函数

#### Deep Q Learning中的Experience Replay是什么？
* Experience Replay又称“经验池”，是将每个时间步Agent于环境交互得到的转移样本储存起来<img src="http://latex.codecogs.com/gif.latex?(S_{t},A_{t},R_{t},S_{t+1})">，然后训练时随机采样样本更新深度神经网络的参数。

#### REINFORCE模型是什么？
* REINFORCE是policy based的强化学习模型，只有状态State和奖励Reward，将状态的转移作为决策的结果。

#### 程序实现树转化成序列，实现序列转化成树？
    def Seqlize(tree):
      if !tree:
         

#### 有一个m长的数列，设计算法取出其中最大的10个数；如何优化算法，使算法复杂度达到<img src="http://latex.codecogs.com/gif.latex?O(mlog10)">和<img src="http://latex.codecogs.com/gif.latex?O(m)">
* 取头10个数值降序存入10长度的数列中，向后遍历原数列，将新值与数列中的数进行比较，如大于最小值则插入适当位置保持数列降序，小于最小值泽忽略，不断更新数列直到遍历完成；时间复杂度为10m。将10长度的数列变成堆；时间复杂度为<img src="http://latex.codecogs.com/gif.latex?mlog10">。
 
#### 快排的原理是怎么样的？快排的复杂度是多少？
* 简单而言，快排的原理是。快排的平均复杂度是<img src="http://latex.codecogs.com/gif.latex?nlogn">，最坏情况是<img src="http://latex.codecogs.com/gif.latex?n^{2}">。

#### 手推GBDT与XGBoost
* http://blog.csdn.net/asd136912/article/details/78556362
* https://www.jianshu.com/p/7467e616f227

#### XGBoost中shrinkage
* Shrinkage（缩减），即学习速率 将学习速率调小，迭代次数增多，有正则化作用


